# model
pretrain_l_m: none  # bert-base, none,xlnet-base, xlnet-large

# encoder
word_dim: 100
lstm_dim: 128
out_dim: 128
type_dim: 20
coref_dim: 20
bilstm_layers: 1
rgcn_hidden_dim: 128
rgcn_num_layers: 2

# dep gcn model
adj_is_sparse: true
gat_flag: false
contextgcn: true
gcn_in_drop: 0.2
gcn_out_drop: 0.0
gcn_hidden_dim: 128
gcn_att_dim: 64
gcn_num_layers: 2

# entity-mention-sentence graph
edge_out_dim: 128
beta: 0.8
dist_dim: 20
walks_iter: 4
types: true
context: true  # MM
dist: true  # MM SS
finaldist: true  # EE  # it is good
edges: ['MM', 'ME', 'MS', 'ES', 'SS-ind'] ## SS-ind

# network
batch: 2
epoch: 200
drop_i: 0.3 # 0.5
drop_m: 0.0
drop_o: 0.2 # 0.3
lr: 0.001
bert_lr: 0.00001
lr_decay_rate: 0.1
lr_decay_step: 2000
gc: 10
reg: 0.0000
opt: adam
loss_weight: false
patience: 10
unk_w_prob: 0.2
min_w_freq: 1
init_train_epochs: 20
NA_NUM: 0.3  # 0.1==5:1

# data based
dep_adj_no_split: true
train_data: ../data/DocPRE/processed/train1_v2.json  # 91 epoch 0.3693
test_data: ../data/DocPRE/processed/dev1_v2.json
embeds: true
folder: ../results/docpre-dev
save_pred: dev

# options (chosen from parse input otherwise false)
lowercase: true
plot: true
show_class: false
param_avg: false
early_stop: true
save_model: true
freeze_words: true
re_train: true

# extra
seed: 0
shuffle_data: true
label2ignore: unknown
primary_metric: micro_f
