# model
dataset: PRE_data
# data based
train_data: ../data/DocPRE/processed/data_v3.json
test_data: ../data/DocPRE/processed/dev1_v3.json
emb_method_file: merge
embeds: ../data/DocPRE/word_vector/sgns.merge.word
folder: ../results/docpre-dev-merge-v3-new
save_pred: dev
remodelfile: ../results/docpre-dev-merge-v3-new/docred_full-tmp
output_path: ../results/docpre-dev-merge-v3-new/docred_full-tmp
# features
global_rep: true
doc_node: true
more_gru: true
pretrain_l_m:  none # tx, bert-base-chinese,bert-base,chinese, none,xlnet-base, xlnet-large
lstm_encoder: false
more_lstm: false

query: global # global
# encoder
emb_method: true # true for load_embeds
emb_method_file_path: ../data/DocPRE/word_vector/processed/
word_dim: 300
lstm_dim: 256
out_dim: 256
dist_dim: 20
finaldist: true
bilstm_layers: 1
rgcn_hidden_dim: 256
rgcn_num_layers: 2
gcn_in_drop: 0.2
gcn_out_drop: 0.2

# network
batch: 8
epoch: 50
drop_i: 0.5 # 0.5
drop_m: 0.0
drop_o: 0.3 # 0.3
lr: 0.0005
bert_lr: 0.00001
gc: 10
reg: 0.000
opt: adam
patience: 10
unk_w_prob: 0.5
min_w_freq: 1
init_train_epochs: 1
NA_NUM: 0.5  # 0.1==5:1
mlp_layers: 1
mlp_dim: 512

# gru
add_pos : true
pos_limit : 15  # 词与实体最大的距离
pos_dim : 5  # 设置位置嵌入的维度
input_gru: 256
gru_dim: 256
output_gru: 256
gru_layers: 2
gru_dropout: 0.5  # 失活概率：0.5
word_attn: true
sent_attn: true

# options (chosen from parse input otherwise false)
plot: true
show_class: true
early_stop: true
save_model: true
freeze_words: true

# extra
seed: 6
shuffle_data: true
label2ignore: NA
primary_metric: micro_f
gpu: 0